{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibK1xUOGSDm",
        "outputId": "8c2fa14e-760b-43e3-a41f-98b2d65eade7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [SYSTEM] Initializing Enterprise Environment...\n",
            " [INSTALL] Installing High-Performance Dependencies...\n",
            " [PATCH] Scanning system for broken 'basicsr' module...\n",
            " [INFO] System appears clean or already patched.\n",
            " [CACHE] InSwapper Model found locally.\n",
            " [CACHE] GFPGAN Face Enhancer found locally.\n",
            " [CACHE] RealESRGAN Upscaler found locally.\n",
            " [BOOT] Starting AI Engines...\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "inswapper-shape: [1, 3, 128, 128]\n",
            " [CONFIG] Configuring Upscaler for Maximum Coherence...\n",
            " [READY] All AI Systems Operational.\n",
            "\n",
            "\n",
            " [NETWORK] TUNNEL ESTABLISHED\n",
            " [LINK] >>>> https://braelynn-milkier-stephanie.ngrok-free.dev <<<<\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "WARNING:pyngrok.process.ngrok:t=2025-11-20T12:27:09+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Nov/2025 12:27:29] \"OPTIONS / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Nov/2025 12:27:30] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Nov/2025 12:28:03] \"OPTIONS /swap HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Nov/2025 12:28:13] \"POST /swap HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "# --- ENTERPRISE GRADE FACE SWAP SERVER (v2.1 - NO SCRAMBLE FIX) ---\n",
        "# Engineered by R H A Ashan Imalka ( SCXR )\n",
        "# Focus: Stability, Error-Correction, High Performance, ZERO ARTIFACTS\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import site\n",
        "import shutil\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 1: ENVIRONMENT PREPARATION\n",
        "# ==========================================\n",
        "\n",
        "print(\" [SYSTEM] Initializing Enterprise Environment...\")\n",
        "print(\" [INSTALL] Installing High-Performance Dependencies...\")\n",
        "\n",
        "!pip install insightface==0.7.3 onnxruntime-gpu flask flask-cors pyngrok gfpgan basicsr realesrgan > /dev/null 2>&1\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 2: SURGICAL PATCHING (THE FIX)\n",
        "# ==========================================\n",
        "def patch_broken_dependency():\n",
        "    print(\" [PATCH] Scanning system for broken 'basicsr' module...\")\n",
        "    possible_paths = site.getsitepackages()\n",
        "    if hasattr(site, 'getusersitepackages'):\n",
        "        possible_paths.append(site.getusersitepackages())\n",
        "\n",
        "    patch_count = 0\n",
        "    for package_dir in possible_paths:\n",
        "        target_file = os.path.join(package_dir, 'basicsr', 'data', 'degradations.py')\n",
        "        if os.path.exists(target_file):\n",
        "            try:\n",
        "                with open(target_file, 'r') as f:\n",
        "                    code = f.read()\n",
        "                bad_import = 'from torchvision.transforms.functional_tensor import rgb_to_grayscale'\n",
        "                good_import = 'from torchvision.transforms.functional import rgb_to_grayscale'\n",
        "                if bad_import in code:\n",
        "                    print(\" [PATCH] Applying surgical fix...\")\n",
        "                    new_code = code.replace(bad_import, good_import)\n",
        "                    with open(target_file, 'w') as f:\n",
        "                        f.write(new_code)\n",
        "                    patch_count += 1\n",
        "                    print(\" [SUCCESS] Module patched.\")\n",
        "            except Exception as e:\n",
        "                print(f\" [ERROR] Patch failed: {e}\")\n",
        "\n",
        "    if patch_count == 0:\n",
        "        print(\" [INFO] System appears clean or already patched.\")\n",
        "\n",
        "patch_broken_dependency()\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 3: MODEL AQUISITION\n",
        "# ==========================================\n",
        "def download_model(url, filename, description):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\" [DOWNLOAD] Retrieving {description}...\")\n",
        "        subprocess.run(['wget', '-q', url, '-O', filename])\n",
        "    else:\n",
        "        print(f\" [CACHE] {description} found locally.\")\n",
        "\n",
        "download_model('https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx', 'inswapper_128.onnx', 'InSwapper Model')\n",
        "download_model('https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth', 'GFPGANv1.4.pth', 'GFPGAN Face Enhancer')\n",
        "download_model('https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth', 'RealESRGAN_x4plus.pth', 'RealESRGAN Upscaler')\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 4: CORE INITIALIZATION\n",
        "# ==========================================\n",
        "print(\" [BOOT] Starting AI Engines...\")\n",
        "\n",
        "import cv2\n",
        "import insightface\n",
        "import numpy as np\n",
        "import base64\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from gfpgan import GFPGANer\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from realesrgan import RealESRGANer\n",
        "\n",
        "# CONFIGURATION\n",
        "NGROK_AUTH_TOKEN = \"35bsndR53PzXmMZoQYQ60IVLB0O_51qEwEWaXvsMvnukGfaeK\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# 1. Detection\n",
        "app_face = insightface.app.FaceAnalysis(name='buffalo_l')\n",
        "app_face.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "# 2. Swapping\n",
        "swapper = insightface.model_zoo.get_model('inswapper_128.onnx', download=False, download_zip=False)\n",
        "\n",
        "# 3. Restoration (GFPGAN)\n",
        "face_enhancer = GFPGANer(model_path='GFPGANv1.4.pth', upscale=1, arch='clean', channel_multiplier=2, bg_upsampler=None)\n",
        "\n",
        "# 4. Upscaling (RealESRGAN)\n",
        "print(\" [CONFIG] Configuring Upscaler for Maximum Coherence...\")\n",
        "model_rrdb = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "bg_upsampler = RealESRGANer(\n",
        "    scale=2,\n",
        "    model_path='RealESRGAN_x4plus.pth',\n",
        "    model=model_rrdb,\n",
        "    tile=0,          # <--- CHANGED TO 0! Disables tiling logic completely. No more scrambled eggs!\n",
        "    tile_pad=10,     # Ignored when tile=0, but kept for safety\n",
        "    pre_pad=0,\n",
        "    half=True\n",
        ")\n",
        "\n",
        "print(\" [READY] All AI Systems Operational.\")\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 5: LOGIC\n",
        "# ==========================================\n",
        "def decode_image(base64_string):\n",
        "    if ',' in base64_string:\n",
        "        base64_string = base64_string.split(',')[1]\n",
        "    img_data = base64.b64decode(base64_string)\n",
        "    nparr = np.frombuffer(img_data, np.uint8)\n",
        "    return cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "def encode_image(cv2_img):\n",
        "    _, buffer = cv2.imencode('.jpg', cv2_img)\n",
        "    return \"data:image/jpeg;base64,\" + base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "def get_largest_face(faces):\n",
        "    if not faces:\n",
        "        return None\n",
        "    return max(faces, key=lambda x: (x.bbox[2] - x.bbox[0]) * (x.bbox[3] - x.bbox[1]))\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Asagi Enterprise Server: ONLINE (No-Scramble Mode)\"\n",
        "\n",
        "@app.route('/swap', methods=['POST'])\n",
        "def swap_faces():\n",
        "    try:\n",
        "        data = request.json\n",
        "        source_b64 = data.get('source')\n",
        "        target_b64 = data.get('target')\n",
        "        do_face_enhance = data.get('face_enhance', False)\n",
        "        do_full_upscale = data.get('full_upscale', False)\n",
        "\n",
        "        if not source_b64 or not target_b64:\n",
        "            return jsonify({'error': 'Missing input payload'}), 400\n",
        "\n",
        "        source_img = decode_image(source_b64)\n",
        "        target_img = decode_image(target_b64)\n",
        "\n",
        "        # Detection\n",
        "        source_faces = app_face.get(source_img)\n",
        "        target_faces = app_face.get(target_img)\n",
        "\n",
        "        if not source_faces:\n",
        "            return jsonify({'error': 'Source: No face detected.'}), 400\n",
        "        if not target_faces:\n",
        "            return jsonify({'error': 'Target: No face detected.'}), 400\n",
        "\n",
        "        source_face = get_largest_face(source_faces)\n",
        "\n",
        "        # Processing\n",
        "        res_img = target_img.copy()\n",
        "\n",
        "        # Swap\n",
        "        for target_face in target_faces:\n",
        "            res_img = swapper.get(res_img, target_face, source_face, paste_back=True)\n",
        "\n",
        "        # Enhance\n",
        "        if do_face_enhance or do_full_upscale:\n",
        "            try:\n",
        "                _, _, res_img = face_enhancer.enhance(res_img, has_aligned=False, only_center_face=False, paste_back=True)\n",
        "            except Exception as e:\n",
        "                print(f\" [WARN] Face Enhance failed: {e}\")\n",
        "\n",
        "        # Upscale\n",
        "        if do_full_upscale:\n",
        "            try:\n",
        "                # With tile=0, this might use a lot of VRAM, but result will be perfect\n",
        "                output, _ = bg_upsampler.enhance(res_img, outscale=2)\n",
        "                res_img = output\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e):\n",
        "                    print(\" [WARN] Image too big for Upscale! Returning normal resolution.\")\n",
        "                    return jsonify({'error': 'Image too big for Ultra Upscale. Try turning off Ultra Upscale.'}), 500\n",
        "                else:\n",
        "                    print(f\" [ERROR] Upscale failed: {e}\")\n",
        "\n",
        "        result_b64 = encode_image(res_img)\n",
        "        return jsonify({'result': result_b64, 'status': 'success'})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" [ERROR] Processing failed: {e}\")\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "# ==========================================\n",
        "# PHASE 6: LAUNCH\n",
        "# ==========================================\n",
        "ngrok.kill()\n",
        "try:\n",
        "    tunnel = ngrok.connect(5000)\n",
        "    public_url = tunnel.public_url\n",
        "    print(f\"\\n\\n [NETWORK] TUNNEL ESTABLISHED\")\n",
        "    print(f\" [LINK] >>>> {public_url} <<<<\")\n",
        "    app.run(port=5000)\n",
        "except Exception as e:\n",
        "    print(f\" [CRITICAL] Network Failure: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
